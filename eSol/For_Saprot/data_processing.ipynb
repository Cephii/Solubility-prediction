{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "11fc7769-a12e-4e35-a08f-a68fe2f61f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "os.chdir('/home/ubuntu/SaprotHub/colab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e78c8e8b-5580-403e-8d92-6152bb23341d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('eSol_output_SA_split.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c92f241d-1575-4300-918a-6862dd435869",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_sequence(sequence):\n",
    "    return sequence[::2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "89b0b0c8-5249-4706-aef6-dc5fa68d58b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sequence_only'] = df['sequence'].apply(extract_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "43a1b17d-46cb-4625-885b-03f8c097f029",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['index'] = [f\"sample_{i+1}\" for i in range(len(df))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cd8e4749-f57c-4f32-87b0-23b456a3a10a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv('expression_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e4f81344-be16-43d8-9efa-d9e62e7cf8b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('exression_data.fasta', 'w') as fasta_file:\n",
    "#     for index, row in df.iterrows():\n",
    "#         fasta_file.write(f\">{row['index']}\\n\")\n",
    "#         fasta_file.write(f\"{row['sequence_only']}\\n\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "46055856-8fdb-4470-aa79-2bb1ac85daf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = 'mmseq2_clusters/expression_si02/clusterRes_cluster.tsv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "37add11e-d978-46b9-a928-e21c00b678e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_clusters(input_filename):\n",
    "    representative_counts = {}\n",
    "    # Open the TSV file and count the members for each representative\n",
    "    with open(input_filename, 'r') as infile:\n",
    "        # Skip the header line\n",
    "        next(infile)\n",
    "        for line in infile:\n",
    "            cluster_representative = line.split(\"\\t\")[0].strip()\n",
    "            # Increment the count for this representative or set to 1 if it’s the first occurrence\n",
    "            representative_counts[cluster_representative] = representative_counts.get(cluster_representative, 0) + 1\n",
    "    # Filter out representatives with only 1 member\n",
    "    filtered_representatives = {rep: count for rep, count in representative_counts.items() if count > 0}\n",
    "    # Print the results\n",
    "    # Uncomment if you want to print individual representative counts\n",
    "    # for rep, count in filtered_representatives.items():\n",
    "    #     print(f”{rep}: {count} members”)\n",
    "    # Print the total number of remaining representatives\n",
    "    print(f\"\\nTotal number of representatives with more than one member for file '{input_filename}': {len(filtered_representatives)}\")\n",
    "    return filtered_representatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "38defc2d-d5ec-4e87-99d0-329dc60d4bb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total number of representatives with more than one member for file 'mmseq2_clusters/expression_si02/clusterRes_cluster.tsv': 2442\n"
     ]
    }
   ],
   "source": [
    "reps_count_si02= process_clusters(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "43d2ba66-9091-4e83-9410-037ff11d0861",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pdb_clusters(input_filename):\n",
    "    representative_counts = {}\n",
    "    representative_files = {}  # Store the PDB files associated with each representative\n",
    "    pdb_pattern = re.compile('sample')  # Regular expression pattern to match any 5-letter name before .pdb\n",
    "    # Create a dictionary to store matches for each representative\n",
    "    matches_dict = {}\n",
    "    cluster_number = 1\n",
    "    # Open the TSV file and count the members for each representative\n",
    "    with open(input_filename, 'r') as infile:\n",
    "        # Skip the header line\n",
    "        next(infile)\n",
    "        for line in infile:\n",
    "            line_parts = line.split(\"\\t\")\n",
    "            cluster_representative, pdb_file = line_parts[0].strip(), line_parts[1].strip()\n",
    "            # Increment the count for this representative or set to 1 if it's the first occurrence\n",
    "            representative_counts[cluster_representative] = representative_counts.get(cluster_representative, 0) + 1\n",
    "            # Append the PDB file associated with this representative\n",
    "            if cluster_representative in representative_files:\n",
    "                representative_files[cluster_representative].append(pdb_file)\n",
    "            else:\n",
    "                representative_files[cluster_representative] = [pdb_file]\n",
    "    # Code moved outside of the loop to process pdb_file and update matches_dict\n",
    "    for cluster_representative, pdb_files in representative_files.items():\n",
    "        matches = []\n",
    "        for pdb_file in pdb_files:\n",
    "            pdb_matches = pdb_pattern.findall(pdb_file)\n",
    "            if len(pdb_matches) > 0:\n",
    "                matches.append(pdb_matches[0])\n",
    "        if len(matches) > 0:\n",
    "            matches_dict[cluster_representative] = matches\n",
    "        else:\n",
    "            matches_dict[cluster_representative] = None\n",
    "    # Filter out representatives with only 1 member\n",
    "    filtered_representatives = {rep: count for rep, count in representative_counts.items() if count > 0}\n",
    "    # Create a dictionary to store the results\n",
    "    results_dict = {}\n",
    "    # Process the results and store them in the results_dict\n",
    "    for rep, count in filtered_representatives.items():\n",
    "        pdb_files = representative_files[rep]\n",
    "        matches = matches_dict[rep]\n",
    "        # if matches is not None:\n",
    "        #     print(matches)\n",
    "        #     # Replace matches in each PDB file once\n",
    "        #     for i in range(len(pdb_files)):\n",
    "        #         pdb_files[i] = pdb_pattern.sub(lambda x: x.group() + '.pdb (rcsb structure)', pdb_files[i])\n",
    "        pdb_files_str = pdb_files if pdb_files else \"None\"\n",
    "        # Store the results in the results_dict\n",
    "        results_dict[rep] = {\n",
    "            \"Count\": count,\n",
    "            \"PDB Files\": pdb_files_str,\n",
    "            \"Matches\": matches,\n",
    "            \"Cluster\": cluster_number\n",
    "        }\n",
    "        \n",
    "        cluster_number+=1\n",
    "    return results_dict\n",
    "\n",
    "def print_results_with_pdb(results_dict):\n",
    "    match_dict ={}\n",
    "    for rep, result in results_dict.items():\n",
    "        matches = result[\"Matches\"]\n",
    "        pdb_files_str = result[\"PDB Files\"]\n",
    "        if matches != \"None\":\n",
    "            if matches is not None:\n",
    "                matches_str = ', '.join(matches)  # Convert matches list to a comma-separated string\n",
    "                # print(f\"Cluster Representative: {rep}, Count: {result['Count']}, len_matches: {len(matches)}, Cluster:{result['Cluster']}\")\n",
    "                match_dict[rep] = {\n",
    "                    \"Count\": result['Count'],\n",
    "                    \"PDB Files\": pdb_files_str,\n",
    "                    \"rcsb_matches\": matches_str,\n",
    "                    \"len_matches\": len(matches),\n",
    "                    \"Cluster\": result[\"Cluster\"]  \n",
    "                }\n",
    "    return match_dict\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fe3a30b3-b848-4c1a-aac8-5a0a94a89819",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "expression_si02_dict = get_pdb_clusters(file)\n",
    "match_dict_si02 = print_results_with_pdb(expression_si02_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b97c3a22-3241-4056-8f2c-480c3eb02153",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_pdb_train =  [match_dict_si02[clust][\"PDB Files\"] for clust in match_dict_si02]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b11fbd77-9bdf-4312-826d-56f52e7fbc92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3150"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([len(a) for a in exp_pdb_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d37533e3-2989-4998-b0fa-49ad48aabfbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = 2800\n",
    "val_size = 200\n",
    "test_size = 150\n",
    "\n",
    "cluster_index= 0\n",
    "len_train =0\n",
    "for i, cluster in enumerate(exp_pdb_train):\n",
    "    if len_train < train_size:\n",
    "        len_train+=len(cluster)\n",
    "        cluster_index = i\n",
    "\n",
    "train_cluster_index =  cluster_index\n",
    "len_val =0 \n",
    "for i, cluster in enumerate(exp_pdb_train[train_cluster_index+1:]):\n",
    "    if len_val < val_size:\n",
    "        len_val+=len(cluster)\n",
    "        cluster_index = i+train_cluster_index\n",
    "\n",
    "val_cluster_index = cluster_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cb6d8cf8-4735-465b-9a05-70b9c40ff5b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset= [item for sublist in exp_pdb_train[:train_cluster_index] for item in sublist]\n",
    "val_dataset = [item for sublist in exp_pdb_train[train_cluster_index+1:val_cluster_index] for item in sublist]\n",
    "test_dataset =[item for sublist in exp_pdb_train[val_cluster_index+1:] for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0225b10a-5a09-4ad1-b673-51fa97372516",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_splits = pd.read_csv('expression_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "495045df-2191-472e-afb6-cf67c202b7e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_splits.loc[df['index'].isin(train_dataset), 'stage']='train'\n",
    "df_splits.loc[df['index'].isin(val_dataset), 'stage']='val'\n",
    "df_splits.loc[df['index'].isin(test_dataset), 'stage']='test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9653f9d4-f077-4df7-ace8-030607b4cf0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sequence</th>\n",
       "      <th>label</th>\n",
       "      <th>stage</th>\n",
       "      <th>sequence_only</th>\n",
       "      <th>index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MdVwKkVkYwAfPaAwSkSfAfNpMlSlVfGdFhDlVfLkGiAfAg...</td>\n",
       "      <td>0.32</td>\n",
       "      <td>train</td>\n",
       "      <td>MVKVYAPASSANMSVGFDVLGAAVTPVDGALLGDVVTVEAAETFSL...</td>\n",
       "      <td>sample_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MdKwLwYaNfLlKvDhHrNvEdQiVdSaFlAlQvAlVlTlQlGlLa...</td>\n",
       "      <td>0.18</td>\n",
       "      <td>train</td>\n",
       "      <td>MKLYNLKDHNEQVSFAQAVTQGLGKNQGLFFPHDLPEFSLTEIDEM...</td>\n",
       "      <td>sample_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>M#K#K#M#Q#S#I#V#L#A#L#S#L#V#L#V#A#P#M#A#A#Q#A#...</td>\n",
       "      <td>0.78</td>\n",
       "      <td>train</td>\n",
       "      <td>MKKMQSIVLALSLVLVAPMAAQAAEITLVPSVKLQIGDRDNRGYYW...</td>\n",
       "      <td>sample_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MdLaIeLeIaSePfAaKqTaLwDdYlQpSdPdLdTlTdTpRdYaTd...</td>\n",
       "      <td>0.07</td>\n",
       "      <td>train</td>\n",
       "      <td>MLILISPAKTLDYQSPLTTTRYTLPELLDNSQQLIHEARKLTPPQI...</td>\n",
       "      <td>sample_4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>M#TdDfKqLlTnSqLlRvQvYqTaTqVeVeAaDeTaGlDdIpAvAl...</td>\n",
       "      <td>0.85</td>\n",
       "      <td>train</td>\n",
       "      <td>MTDKLTSLRQYTTVVADTGDIAAMKLYQPQDATTNPSLILNAAQIP...</td>\n",
       "      <td>sample_5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3146</th>\n",
       "      <td>MdKeIeFaQaRaYdNdPlLlQvVvAlKvYvVlKlIvLdFqRwGdRk...</td>\n",
       "      <td>0.78</td>\n",
       "      <td>train</td>\n",
       "      <td>MKIFQRYNPLQVAKYVKILFRGRLYIKDVGAFEFDKGKILIPKVKD...</td>\n",
       "      <td>sample_3147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3147</th>\n",
       "      <td>MdRkIaFwVfYqGkS#L#R#H#K#Q#G#N#S#H#W#M#T#N#AkQa...</td>\n",
       "      <td>0.98</td>\n",
       "      <td>train</td>\n",
       "      <td>MRIFVYGSLRHKQGNSHWMTNAQLLGDFSIDNYQLYSLGHYPGAVP...</td>\n",
       "      <td>sample_3148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3148</th>\n",
       "      <td>M#V#K#K#S#EpFdEaRaGqDfIwVkLwVfGaFpDpPpAdSdGdHp...</td>\n",
       "      <td>0.94</td>\n",
       "      <td>train</td>\n",
       "      <td>MVKKSEFERGDIVLVGFDPASGHEQQGAGRPALVLSVQAFNQLGMT...</td>\n",
       "      <td>sample_3149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3149</th>\n",
       "      <td>MdNaYwHaQdYwYdPlVfDdIpVqNqGdPhGdTtRaCiTeLtFaVa...</td>\n",
       "      <td>0.69</td>\n",
       "      <td>train</td>\n",
       "      <td>MNYHQYYPVDIVNGPGTRCTLFVSGCVHECPGCYNKSTWRVNSGQP...</td>\n",
       "      <td>sample_3150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3150</th>\n",
       "      <td>MdSkKdTaIqAdTdElNqAaPaAqAdIpGdPpYdVgQqGwVmDdLp...</td>\n",
       "      <td>0.76</td>\n",
       "      <td>train</td>\n",
       "      <td>MSKTIATENAPAAIGPYVQGVDLGNMIITSGQIPVNPKTGEVPADV...</td>\n",
       "      <td>sample_3151</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2802 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               sequence  label  stage  \\\n",
       "0     MdVwKkVkYwAfPaAwSkSfAfNpMlSlVfGdFhDlVfLkGiAfAg...   0.32  train   \n",
       "1     MdKwLwYaNfLlKvDhHrNvEdQiVdSaFlAlQvAlVlTlQlGlLa...   0.18  train   \n",
       "2     M#K#K#M#Q#S#I#V#L#A#L#S#L#V#L#V#A#P#M#A#A#Q#A#...   0.78  train   \n",
       "3     MdLaIeLeIaSePfAaKqTaLwDdYlQpSdPdLdTlTdTpRdYaTd...   0.07  train   \n",
       "4     M#TdDfKqLlTnSqLlRvQvYqTaTqVeVeAaDeTaGlDdIpAvAl...   0.85  train   \n",
       "...                                                 ...    ...    ...   \n",
       "3146  MdKeIeFaQaRaYdNdPlLlQvVvAlKvYvVlKlIvLdFqRwGdRk...   0.78  train   \n",
       "3147  MdRkIaFwVfYqGkS#L#R#H#K#Q#G#N#S#H#W#M#T#N#AkQa...   0.98  train   \n",
       "3148  M#V#K#K#S#EpFdEaRaGqDfIwVkLwVfGaFpDpPpAdSdGdHp...   0.94  train   \n",
       "3149  MdNaYwHaQdYwYdPlVfDdIpVqNqGdPhGdTtRaCiTeLtFaVa...   0.69  train   \n",
       "3150  MdSkKdTaIqAdTdElNqAaPaAqAdIpGdPpYdVgQqGwVmDdLp...   0.76  train   \n",
       "\n",
       "                                          sequence_only        index  \n",
       "0     MVKVYAPASSANMSVGFDVLGAAVTPVDGALLGDVVTVEAAETFSL...     sample_1  \n",
       "1     MKLYNLKDHNEQVSFAQAVTQGLGKNQGLFFPHDLPEFSLTEIDEM...     sample_2  \n",
       "2     MKKMQSIVLALSLVLVAPMAAQAAEITLVPSVKLQIGDRDNRGYYW...     sample_3  \n",
       "3     MLILISPAKTLDYQSPLTTTRYTLPELLDNSQQLIHEARKLTPPQI...     sample_4  \n",
       "4     MTDKLTSLRQYTTVVADTGDIAAMKLYQPQDATTNPSLILNAAQIP...     sample_5  \n",
       "...                                                 ...          ...  \n",
       "3146  MKIFQRYNPLQVAKYVKILFRGRLYIKDVGAFEFDKGKILIPKVKD...  sample_3147  \n",
       "3147  MRIFVYGSLRHKQGNSHWMTNAQLLGDFSIDNYQLYSLGHYPGAVP...  sample_3148  \n",
       "3148  MVKKSEFERGDIVLVGFDPASGHEQQGAGRPALVLSVQAFNQLGMT...  sample_3149  \n",
       "3149  MNYHQYYPVDIVNGPGTRCTLFVSGCVHECPGCYNKSTWRVNSGQP...  sample_3150  \n",
       "3150  MSKTIATENAPAAIGPYVQGVDLGNMIITSGQIPVNPKTGEVPADV...  sample_3151  \n",
       "\n",
       "[2802 rows x 5 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_splits.to_csv('eSol_output_SA_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7ad5c9e4-a20b-439b-9696-b9086f514b5e",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_44071/3785606675.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mtest_proteins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mrepres_counts_si01_PDB\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mclust\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'PDB Files'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mclust\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_items\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mtrain_proteins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_proteins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0mdev_proteins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdev_proteins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m     \u001b[0mtest_proteins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_proteins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "DEV_SIZE= 0.1\n",
    "TEST_SIZE = 0.1\n",
    "\n",
    "sum_total = sum(item['Count'] for item in expression_si02_dict.values())\n",
    "# Calculate target lengths once and store them\n",
    "dev_target_length = round(sum_total * DEV_SIZE * 0.9)\n",
    "test_target_length = round(sum_total * DEV_SIZE * 1.1)\n",
    "# Convert match_dict_si02 into a set for faster membership checking\n",
    "match_dict_si02_set = set(match_dict_si02)\n",
    "merged_keys = [key for key in expression_si02_dict.keys() if key not in match_dict_si02_set]\n",
    "exp_pdb_train =  [match_dict_si02[clust][\"PDB Files\"] for clust in match_dict_si02]\n",
    "exp_pdb_train = list(exp_pdb_train)\n",
    "while True:\n",
    "    indices = np.random.permutation(len(merged_keys))\n",
    "    train_size = 1 - DEV_SIZE - TEST_SIZE\n",
    "    train_idx = indices[: int(train_size * len(merged_keys))]\n",
    "    dev_idx = indices[int(train_size * len(merged_keys)) : int((train_size + DEV_SIZE) * len(merged_keys))]\n",
    "    test_idx = indices[int((train_size + DEV_SIZE) * len(merged_keys)) :]\n",
    "    train_items = [merged_keys[i] for i in train_idx]\n",
    "    dev_items = [merged_keys[i] for i in dev_idx]\n",
    "    test_items = [merged_keys[i] for i in test_idx]\n",
    "    train_proteins = [repres_counts_si01_PDB[clust]['PDB Files'] for clust in train_items]\n",
    "    dev_proteins = [repres_counts_si01_PDB[clust]['PDB Files'] for clust in dev_items]\n",
    "    test_proteins = [repres_counts_si01_PDB[clust]['PDB Files'] for clust in test_items]\n",
    "    train_proteins = list(train_proteins)\n",
    "    dev_proteins = list(dev_proteins)\n",
    "    test_proteins = list(test_proteins)\n",
    "    \n",
    "    train_proteins+=exp_pdb_train\n",
    "    \n",
    "    # Check if the lengths of dev_proteins and test_proteins are within the target range\n",
    "    if dev_target_length <= len(dev_proteins) <= test_target_length and \\\n",
    "       dev_target_length <= len(test_proteins) <= test_target_length:\n",
    "        break  # Exit the loop if the condition is met\n",
    "print('Per chain sizes:')\n",
    "print(\"Train size: \", len(train_proteins))\n",
    "print(\"Dev size: \", len(dev_proteins))\n",
    "print(\"Test size: \", len(test_proteins))\n",
    "print(\"Train size percentage: \",  len(train_proteins)*100/sum_total)\n",
    "print(\"Dev size percentage: \", len(dev_proteins)*100/sum_total)\n",
    "print(\"Test size percentage: \", len(test_proteins)*100/sum_total)\n",
    "print(\"Train clusters: \", len(train_items))\n",
    "print(\"Dev clusters: \", len(dev_items))\n",
    "print(\"Test clusters: \", len(test_items))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "305c8ca4-27fd-4427-b80a-bc9aa6fb10dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
